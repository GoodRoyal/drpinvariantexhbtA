"""
Smoke tests for Layer 6 integration examples.

These tests call each example's main() with captured stdout to verify:
- No exceptions are raised
- Key output strings are present
- CLARA proof depth requirement is met (≤10 levels)
"""
import io
import pytest
import numpy as np
from contextlib import redirect_stdout


# ── toy_prime_encoding ────────────────────────────────────────────────────────

def test_toy_prime_encoding_runs_without_error():
    """main() must complete without raising."""
    np.random.seed(0)
    from examples.toy_prime_encoding import main
    f = io.StringIO()
    with redirect_stdout(f):
        main()


def test_toy_prime_encoding_output_contains_phase_headers():
    """Output must contain the three phase headers."""
    np.random.seed(0)
    from examples.toy_prime_encoding import main
    f = io.StringIO()
    with redirect_stdout(f):
        main()
    out = f.getvalue()
    assert "Phase 1" in out
    assert "Phase 2" in out
    assert "Phase 3" in out


def test_toy_prime_encoding_reports_clara_depth():
    """Output must report the proof depth and the CLARA requirement."""
    np.random.seed(0)
    from examples.toy_prime_encoding import main
    f = io.StringIO()
    with redirect_stdout(f):
        main()
    out = f.getvalue()
    assert "CLARA requirement" in out
    assert "Proof depth" in out


def test_toy_prime_encoding_proof_depth_within_clara_limit():
    """The proof generated by toy_prime_encoding must be ≤ 10 levels deep."""
    np.random.seed(0)
    from core.coordination_controller import CoordinationController
    from core.lossy_translation import LossyTranslator
    from core.proof_generator import ProofGenerator

    PRIME_MAP = {1: 2, 2: 3, 3: 5, 4: 7, 5: 11, 6: 13, 7: 17, 8: 19, 9: 23, 10: 29}
    controller = CoordinationController(persistence_threshold=0.75, window_size=50)
    proof_gen = ProofGenerator()

    for cycle in range(100):
        event_count = (cycle % 7) + 1
        prime_value = PRIME_MAP[event_count]
        mod_record = LossyTranslator.modular_reduction(float(prime_value), modulus=4)
        controller.step({
            "agent_a_count": event_count / 10.0,
            "agent_b_prime": prime_value / 29.0,
            "agent_c_mod4": mod_record.output_value / 3.0,
        })

    all_invariants = controller.detector.detect_all()
    proof = proof_gen.generate_system_proof(
        invariants=all_invariants,
        system_name="Prime-Encoding Coordination System"
    )
    assert proof.depth() <= 10


# ── medical_multicondition ────────────────────────────────────────────────────

def test_medical_multicondition_runs_without_error():
    """main() must complete without raising."""
    from examples.medical_multicondition import main
    f = io.StringIO()
    with redirect_stdout(f):
        main()


def test_medical_multicondition_output_contains_clara_header():
    """Output must mention CLARA TA1."""
    from examples.medical_multicondition import main
    f = io.StringIO()
    with redirect_stdout(f):
        main()
    out = f.getvalue()
    assert "CLARA TA1" in out


def test_medical_multicondition_processes_all_patients():
    """Output must confirm all 200 patients were processed."""
    from examples.medical_multicondition import main
    f = io.StringIO()
    with redirect_stdout(f):
        main()
    out = f.getvalue()
    assert "200 patients" in out


def test_medical_multicondition_proof_depth_within_clara_limit():
    """Pipeline proof must be ≤ 10 levels deep."""
    import torch
    from examples.medical_multicondition import generate_patient_data, MEDICAL_RULES
    from composition.nn_component import NNComponent, SimpleRiskNN
    from composition.problog_component import ProbLogComponent
    from composition.pipeline import CompositionPipeline

    nn_comp = NNComponent(
        SimpleRiskNN(input_dim=8, hidden_dim=32, output_dim=3),
        output_names=["risk_drug_a", "risk_drug_b", "risk_interaction"]
    )
    lp_comp = ProbLogComponent()
    lp_comp.load_rules(MEDICAL_RULES)
    pipeline = CompositionPipeline(
        nn_component=nn_comp,
        lp_component=lp_comp,
        translation_config={
            "risk_drug_a": ("threshold", {"threshold": 0.5}),
            "risk_drug_b": ("threshold", {"threshold": 0.5}),
            "risk_interaction": ("threshold", {"threshold": 0.4}),
        },
        persistence_threshold=0.75
    )

    patients = generate_patient_data(n_patients=200)
    for i in range(len(patients)):
        pipeline.run(patients[i])

    proof = pipeline.generate_proof(system_name="Medical Multi-Condition Guidance")
    assert proof.depth() <= 10


def test_medical_human_edit_takes_effect():
    """Adding a contraindication rule must reduce or preserve safe(drug_a) probability."""
    import torch
    from examples.medical_multicondition import generate_patient_data, MEDICAL_RULES
    from composition.nn_component import NNComponent, SimpleRiskNN
    from composition.problog_component import ProbLogComponent
    from composition.pipeline import CompositionPipeline

    nn_comp = NNComponent(
        SimpleRiskNN(input_dim=8, hidden_dim=32, output_dim=3),
        output_names=["risk_drug_a", "risk_drug_b", "risk_interaction"]
    )
    lp_comp = ProbLogComponent()
    lp_comp.load_rules(MEDICAL_RULES)
    pipeline = CompositionPipeline(
        nn_component=nn_comp,
        lp_component=lp_comp,
        persistence_threshold=0.75
    )

    patient = generate_patient_data(n_patients=1)[0]

    result_before = pipeline.run(patient)
    safe_before = result_before.lp_output.query_results.get("safe(drug_a)", 0.0)

    lp_comp.add_rule("contraindicated(drug_a) :- condition(renal_failure).")
    result_after = pipeline.run(patient, additional_evidence={"condition(renal_failure)": True})
    safe_after = result_after.lp_output.query_results.get("safe(drug_a)", 0.0)

    # With renal failure evidence and the new contraindication rule,
    # safe probability must not increase
    assert safe_after <= safe_before + 1e-9


def test_medical_multicondition_detected_invariants_list():
    """After 200 patients the detector must have processed enough observations."""
    import torch
    from examples.medical_multicondition import generate_patient_data, MEDICAL_RULES
    from composition.nn_component import NNComponent, SimpleRiskNN
    from composition.problog_component import ProbLogComponent
    from composition.pipeline import CompositionPipeline

    nn_comp = NNComponent(
        SimpleRiskNN(input_dim=8, hidden_dim=32, output_dim=3),
        output_names=["risk_drug_a", "risk_drug_b", "risk_interaction"]
    )
    lp_comp = ProbLogComponent()
    lp_comp.load_rules(MEDICAL_RULES)
    pipeline = CompositionPipeline(
        nn_component=nn_comp,
        lp_component=lp_comp,
        persistence_threshold=0.75
    )

    patients = generate_patient_data(n_patients=200)
    for p in patients:
        pipeline.run(p)

    all_inv = pipeline.controller.detector.detect_all()
    # With 200 observations the detector should find at least some invariants
    assert isinstance(all_inv, list)
    assert pipeline.cycle_count == 200
